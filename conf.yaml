# Finish configuration for slower but more stable training
behaviors:
    Crane:
        trainer_type: ppo
        hyperparameters:
            batch_size: 512
            buffer_size: 4096
            learning_rate: 1e-3
            beta: 0.01
            epsilon: 0.2
            lambd: 0.95
            num_epoch: 3 #3
            learning_rate_schedule: linear
        network_settings:
            normalize: false
            hidden_units: 256
            num_layers: 2
            vis_encode_type: simple
        reward_signals:
            extrinsic:
                gamma: 0.99
                strength: 1.0
            curiosity:
                gamma: 0.99
                strength: 0.02
                encoding_size: 256
                learning_rate: 1e-3
        keep_checkpoints: 10
        checkpoint_interval: 500000
        max_steps: 1e08
        time_horizon: 64
        summary_freq: 10000
        threaded: true

# Add this section
environment_parameters:
    level_parameter:
        curriculum:
            - name: Swing control
              completion_criteria:
                  measure: reward
                  behavior: Crane
                  signal_smoothing: true
                  min_lesson_length: 1000
                  threshold: 0.9
              value: 1

            - name: Swing and winch control
              completion_criteria:
                  measure: reward
                  behavior: Crane
                  signal_smoothing: true
                  min_lesson_length: 10000
                  threshold: 1.5
              value: 2

            - name: End
              completion_criteria:
                  measure: reward
                  behavior: Crane
                  signal_smoothing: true
                  min_lesson_length: 1000
                  threshold: 1
                  require_reset: true
              value: -1
