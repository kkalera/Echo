# Finish configuration for slower but more stable training
env_settings:
    env_path: Build/echo
    num_envs: 1

engine_settings:
    width: 1920
    height: 1080

behaviors:
    Crane:
        trainer_type: sac
        keep_checkpoints: 1000
        checkpoint_interval: 50000
        max_steps: 1e08
        time_horizon: 128
        summary_freq: 30000
        threaded: true

        hyperparameters:
            learning_rate: 0.0003
            learning_rate_schedule: constant
            batch_size: 128
            buffer_size: 2000000
            buffer_init_steps: 1000
            tau: 0.01
            steps_per_update: 10.0
            save_replay_buffer: false
            init_entcoef: 0.01
            reward_signal_steps_per_update: 10.0

        network_settings:
            normalize: false
            hidden_units: 512
            num_layers: 2
            vis_encode_type: simple

        reward_signals:
            extrinsic:
                gamma: 0.99
                strength: 10
            curiosity:
                strength: 0.01
                gamma: 0.99
                encoding_size: 256
            gail:
                strength: 0.01
                gamma: 0.99
                encoding_size: 128
                demo_path: Demos/V3GrabAndPlaceSi.demo

# Add this section
environment_parameters:
    level_parameter:
        curriculum:
            - name: Swing control
              completion_criteria:
                  measure: reward
                  behavior: Crane
                  signal_smoothing: true
                  min_lesson_length: 100000
                  threshold: 2.6
              value: 0

            - name: End
              completion_criteria:
                  measure: reward
                  behavior: Crane
                  signal_smoothing: true
                  min_lesson_length: 100000
                  threshold: 1
                  require_reset: true
              value: -1
