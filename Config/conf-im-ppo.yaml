# Finish configuration for slower but more stable training
behaviors:
    Crane:
        trainer_type: ppo
        keep_checkpoints: 1000
        checkpoint_interval: 50000
        max_steps: 1e08
        time_horizon: 128
        summary_freq: 10000
        threaded: true

        hyperparameters:
            batch_size: 2048
            buffer_size: 20480
            learning_rate: 0.0003
            beta: 1.0e-2
            epsilon: 0.2
            lambd: 0.95
            num_epoch: 3
            learning_rate_schedule: linear

        network_settings:
            normalize: false
            hidden_units: 256
            num_layers: 2
            vis_encode_type: simple

        reward_signals:
            extrinsic:
                strength: 1.0
                gamma: 0.99
            curiosity:
                strength: 0.01
                gamma: 0.99
                encoding_size: 256
            gail:
                strength: 0.01
                gamma: 0.99
                encoding_size: 128
                demo_path: Demos/gp_1.demo

        behavioral_cloning:
            strength: 1
            num_epoch: 2000000       
            demo_path: Demos/gp_1.demo
