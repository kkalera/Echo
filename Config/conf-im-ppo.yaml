# Finish configuration for slower but more stable training
behaviors:
    Crane:
        trainer_type: ppo
        keep_checkpoints: 1000
        checkpoint_interval: 50000
        max_steps: 1e10
        time_horizon: 128
        summary_freq: 10000
        threaded: true

        hyperparameters:
            batch_size: 1024
            buffer_size: 10240
            learning_rate: 0.0003
            beta: 1.0e-2
            epsilon: 0.2
            lambd: 0.95
            num_epoch: 3
            learning_rate_schedule: linear

        network_settings:
            normalize: false
            hidden_units: 256
            num_layers: 2
            vis_encode_type: simple

        reward_signals:
            gail:
                strength: 1
                gamma: 0.99
                encoding_size: 128
                demo_path: Demos/gp_1.demo
